{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\Anaconda3\\Lib\\site-packages')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# For loading tweets to generators\n",
    "from itertools import chain\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read tweets into notebook\n",
    "The name of the game here will be to load tweets with minimum memory usage. My plan is to store the tweets (saved in .json format) in a generator. Then iterate through the object and only store desired information from the tweet. I want to store the following:\n",
    "\n",
    "- text\n",
    "- date created\n",
    "- retweet or original\n",
    "- user\n",
    "- number of likes\n",
    "- number of retweets\n",
    "- number of user followers\n",
    "- number of user following\n",
    "\n",
    "#### Analysis outlook\n",
    "\n",
    "It might be interesting to try and predict things like number of likes based on the last three features. By converting the number of likes into catagories e.g. none (0), low (1-5), moderate(6-15), high(16-100), famous(100+) we are open to a range of machine learning algorithms such as kNN, binary search tree, OvR (one vs. rest) linear models e.g. linear regression and logistic regression. Should choose categories such that each is well represented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read tweets the lazy way with large memory cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Use glob to search through all dates with specific hashtag\n",
    "# # then read the files and load the cumulitive result into a\n",
    "# # list to return\n",
    "\n",
    "# def merge_tweets(file_root, skip=100):\n",
    "#     ''' Function that compiles tweets from multiple files\n",
    "#         into a single list.  This may take a while.\n",
    "        \n",
    "#         file_root - Root directory to folder\n",
    "#         skip (int) - Number of files to skip over before storing\n",
    "#                      a tweet to memory.\n",
    "#         '''\n",
    "#     print(list(glob.iglob(file_root+'*')))\n",
    "#     tweet_files = list(glob.iglob(file_root+'*'))\n",
    "#     tweets = []\n",
    "#     for file in tweet_files:\n",
    "#         with open(file, 'r') as f:\n",
    "#             for i, line in enumerate(f.readlines()):\n",
    "#                     if i%skip == 0:\n",
    "#                         tweets.append(json.loads(line))\n",
    "#         print('finished importing file:', file)\n",
    "#     return tweets\n",
    "#\n",
    "# data = merge_tweets(file_root='#nhl/', skip=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use glob to search through all dates with specific hashtag\n",
    "# then read the files and load the cumulitive result into generator\n",
    "\n",
    "def merge_tweets(file_root, skip=100, file_start=''):\n",
    "    ''' Function that compiles tweets from multiple files\n",
    "        into a single list.  This may take a while.\n",
    "        \n",
    "        file_root (str) - Root directory to folder\n",
    "        skip (int)      - To save memory, skip over\n",
    "                          files using the rule:\n",
    "                          if i%skip == 0. e.g. skip=1\n",
    "                          reads in all tweets because\n",
    "                          i%1 == 0 for all integers i. '''\n",
    "    \n",
    "    if not file_start:\n",
    "        file_start = file_root\n",
    "    file_root = file_root + '/' + file_start + '*'\n",
    "    tweet_files = list(glob.iglob(file_root))\n",
    "    tweets = iter(())\n",
    "    for f in tweet_files:\n",
    "        t = load_tweets(f, skip)\n",
    "        tweets = chain(tweets, t)\n",
    "    return tweets\n",
    "\n",
    "def load_tweets(file, skip):\n",
    "    with open(file, 'r') as f:\n",
    "        tweets = (json.loads(line) for i, line in enumerate(f.readlines()) if i%skip==0)\n",
    "    return tweets\n",
    "    \n",
    "# Put tweets into a dictionary\n",
    "all_tweets = {}\n",
    "\n",
    "# Input folder names\n",
    "search_phrases = ['test_files']\n",
    "\n",
    "for folder in search_phrases:\n",
    "    all_tweets[folder] = merge_tweets(file_root=folder, skip=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_files': <itertools.chain at 0x206a7df0668>}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Iterate through tweets, check for NHL related\n",
    "# phrases in tweet['text'] and save qualifying\n",
    "# tweets to a new file\n",
    "\n",
    "criteria = {'#nhl': ['nhl'],\n",
    "            'test_files': ['nhl'],\n",
    "            'Pavelski': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                         'SJS', 'sjs', 'sharks', 'Sharks',\n",
    "                         'jose', 'Jose', 'Joe'],\n",
    "            'Lucic': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                      'LAK', 'kings', 'Kings',\n",
    "                      'angeles', 'Angeles', 'Milan'],\n",
    "            'Ovechkin': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                         'WSH', 'wsh', 'caps', 'Caps',\n",
    "                         'capitals', 'Capitals',\n",
    "                         'washington', 'Washington',\n",
    "                         'Alex'],\n",
    "            'Giroux': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                       'PHI', 'phi', 'flyers', 'Flyers',\n",
    "                       'Philadelphia', 'Claude'],\n",
    "            'Jagr': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                     'FLA', 'fla', 'panthers', 'Panthers',\n",
    "                     'florida', 'Florida', 'Jaromir'],\n",
    "            'Tavares': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                        'NYI', 'nyi', 'islanders', 'Islanders',\n",
    "                        'york', 'York', 'John'],\n",
    "            'Kucherov': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                         'TBL', 'tbl', 'lightning', 'Lightning',\n",
    "                         'tampa', 'Tampa', 'Nikita'],\n",
    "            'Mrazek': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                       'DET', 'det', 'Wings', 'wings',\n",
    "                       'Detroit', 'Petr'],\n",
    "            'Seguin': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                       'DAL', 'dal', 'stars', 'Stars',\n",
    "                       'Dallas', 'Tyler'],\n",
    "            'Pominville': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                           'MIN', 'min', 'wild', 'Wild',\n",
    "                           'Minnesota', 'Jason'],\n",
    "            'Crosby': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                       'PIT', 'pit', 'penguins', 'Penguins',\n",
    "                       'Pittsburgh', 'Sidney'],\n",
    "            'Lundqvist': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                          'NYR', 'nyr', 'rangers', 'Rangers',\n",
    "                          'york', 'York', 'Henrik'],\n",
    "            'Tarasenko':['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                         'STL', 'stl', 'blues', 'Blues',\n",
    "                         'louis', 'Louis', 'Vladimir'],\n",
    "            'Kane': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                     'CHI', 'chi', 'hawks', 'Hawks',\n",
    "                     'chicago', 'Chicago', 'Patrick'],\n",
    "            'Perry': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                      'ANA', 'ana', 'ducks', 'Ducks',\n",
    "                      'Anaheim', 'Corey'],\n",
    "            'Forsberg': ['NHL', 'nhl', 'hockey', 'Hockey',\n",
    "                         'NSH', 'nsh', 'predators', 'Predators',\n",
    "                         'Nashville', 'Filip']}\n",
    "\n",
    "if True:\n",
    "    for folder in all_tweets.keys():\n",
    "        with open(folder+'/filtered_tweets.json', 'w') as f:\n",
    "            for t in all_tweets[folder]:\n",
    "                for word in criteria[folder]:\n",
    "                    if word in t['text']:\n",
    "                        json.dump(t, f)\n",
    "                        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in filtered tweets\n",
    "\n",
    "# Put tweets into a dictionary\n",
    "all_tweets = {}\n",
    "\n",
    "# Input folder names\n",
    "search_phrases = ['test_files']\n",
    "\n",
    "for folder in search_phrases:\n",
    "    all_tweets[folder] = merge_tweets(file_root=folder, skip=1,\n",
    "                                      file_start='filtered_tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate over generators containing tweets and\n",
    "# append desired information to lists\n",
    "\n",
    "data = {'text': [], 'screen_name': [], 'created_at': [],\n",
    "        'retweet_count': [], 'favorite_count': [],\n",
    "        'friends_count': [], 'followers_count': []}\n",
    "\n",
    "for folder in all_tweets.keys():\n",
    "    for t in all_tweets[folder]:\n",
    "        data['text'].append(t['text'])\n",
    "        data['screen_name'].append(t['user']['screen_name'])\n",
    "        data['created_at'].append(t['created_at'])\n",
    "        data['retweet_count'].append(t['retweet_count'])\n",
    "        data['favorite_count'].append(t['favorite_count'])\n",
    "        data['friends_count'].append(t['user']['friends_count'])\n",
    "        data['followers_count'].append(t['user']['followers_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create pandas dataframe from dictionary\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-17 23:33:28</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>1536</td>\n",
       "      <td>0</td>\n",
       "      <td>WilliamWisson</td>\n",
       "      <td>Hitchcock on round 1 series: \"This feels very ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-17 23:04:29</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>148</td>\n",
       "      <td>103</td>\n",
       "      <td>jenlbyrnes</td>\n",
       "      <td>RT @martinkilcoyne2: Now that's a big screen t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-17 22:46:33</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>101</td>\n",
       "      <td>103</td>\n",
       "      <td>elope2003</td>\n",
       "      <td>RT @martinkilcoyne2: Now that's a big screen t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-17 21:45:24</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>tschatsiek</td>\n",
       "      <td>Capitalize!!!!! #stlblues #nhl #StanleyCupPlay...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-17 21:17:59</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>1536</td>\n",
       "      <td>0</td>\n",
       "      <td>WilliamWisson</td>\n",
       "      <td>Islanders must fix defensive problems on secon...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at  favorite_count  followers_count  friends_count  \\\n",
       "0 2016-04-17 23:33:28               0              191           1536   \n",
       "1 2016-04-17 23:04:29               0               47            148   \n",
       "2 2016-04-17 22:46:33               0              110            101   \n",
       "3 2016-04-17 21:45:24               0               52            363   \n",
       "4 2016-04-17 21:17:59               0              191           1536   \n",
       "\n",
       "   retweet_count    screen_name  \\\n",
       "0              0  WilliamWisson   \n",
       "1            103     jenlbyrnes   \n",
       "2            103      elope2003   \n",
       "3              0     tschatsiek   \n",
       "4              0  WilliamWisson   \n",
       "\n",
       "                                                text     RT  \n",
       "0  Hitchcock on round 1 series: \"This feels very ...  False  \n",
       "1  RT @martinkilcoyne2: Now that's a big screen t...   True  \n",
       "2  RT @martinkilcoyne2: Now that's a big screen t...   True  \n",
       "3  Capitalize!!!!! #stlblues #nhl #StanleyCupPlay...  False  \n",
       "4  Islanders must fix defensive problems on secon...  False  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column for retweet or original\n",
    "\n",
    "RT = []\n",
    "for t in df.text:\n",
    "    RT.append(t.split()[0]=='RT')\n",
    "df['RT'] = RT\n",
    "\n",
    "# Convert created_at to datetimes\n",
    "\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at         datetime64[ns]\n",
       "favorite_count              int64\n",
       "followers_count             int64\n",
       "friends_count               int64\n",
       "retweet_count               int64\n",
       "screen_name                object\n",
       "text                       object\n",
       "RT                           bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.206897</td>\n",
       "      <td>559.793103</td>\n",
       "      <td>887.275862</td>\n",
       "      <td>11.689655</td>\n",
       "      <td>0.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.619868</td>\n",
       "      <td>1026.912376</td>\n",
       "      <td>864.469651</td>\n",
       "      <td>34.667918</td>\n",
       "      <td>0.384426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>706.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>1536.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5376.000000</td>\n",
       "      <td>3909.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       favorite_count  followers_count  friends_count  retweet_count        RT\n",
       "count       29.000000        29.000000      29.000000      29.000000        29\n",
       "mean         0.206897       559.793103     887.275862      11.689655  0.172414\n",
       "std          0.619868      1026.912376     864.469651      34.667918  0.384426\n",
       "min          0.000000        30.000000      25.000000       0.000000     False\n",
       "25%          0.000000       110.000000     144.000000       0.000000         0\n",
       "50%          0.000000       191.000000     706.000000       0.000000         0\n",
       "75%          0.000000       598.000000    1536.000000       0.000000         0\n",
       "max          3.000000      5376.000000    3909.000000     128.000000      True"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
